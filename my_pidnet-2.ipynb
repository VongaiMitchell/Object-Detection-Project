{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DEPENDENCIES**"
      ],
      "metadata": {
        "id": "C0VbutTdjMvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a = []\n",
        "# while(1):\n",
        "#   a.append(\"1\")"
      ],
      "metadata": {
        "id": "hE1tCK5AinaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BatchNorm2d = nn.BatchNorm2d\n",
        "bn_mom = 0.1\n",
        "algc = False"
      ],
      "metadata": {
        "id": "jA8KPnKqjUHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI6Yy8PYi2TJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.no_relu = no_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        if self.no_relu:\n",
        "            return out\n",
        "        else:\n",
        "            return self.relu(out)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 2\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=True):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
        "                               bias=False)\n",
        "        self.bn3 = BatchNorm2d(planes * self.expansion, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.no_relu = no_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        if self.no_relu:\n",
        "            return out\n",
        "        else:\n",
        "            return self.relu(out)\n",
        "\n",
        "class segmenthead(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, interplanes, outplanes, scale_factor=None):\n",
        "        super(segmenthead, self).__init__()\n",
        "        self.bn1 = BatchNorm2d(inplanes, momentum=bn_mom)\n",
        "        self.conv1 = nn.Conv2d(inplanes, interplanes, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(interplanes, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(interplanes, outplanes, kernel_size=1, padding=0, bias=True)\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(self.relu(self.bn1(x)))\n",
        "        out = self.conv2(self.relu(self.bn2(x)))\n",
        "\n",
        "        if self.scale_factor is not None:\n",
        "            height = x.shape[-2] * self.scale_factor\n",
        "            width = x.shape[-1] * self.scale_factor\n",
        "            out = F.interpolate(out,\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "\n",
        "        return out\n",
        "\n",
        "class DAPPM(nn.Module):\n",
        "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
        "        super(DAPPM, self).__init__()\n",
        "        bn_mom = 0.1\n",
        "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale0 = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.process1 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process2 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process3 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process4 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.compression = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.shortcut = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        width = x.shape[-1]\n",
        "        height = x.shape[-2]\n",
        "        x_list = []\n",
        "\n",
        "        x_list.append(self.scale0(x))\n",
        "        x_list.append(self.process1((F.interpolate(self.scale1(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[0])))\n",
        "        x_list.append((self.process2((F.interpolate(self.scale2(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[1]))))\n",
        "        x_list.append(self.process3((F.interpolate(self.scale3(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[2])))\n",
        "        x_list.append(self.process4((F.interpolate(self.scale4(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[3])))\n",
        "\n",
        "        out = self.compression(torch.cat(x_list, 1)) + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "class PAPPM(nn.Module):\n",
        "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
        "        super(PAPPM, self).__init__()\n",
        "        bn_mom = 0.1\n",
        "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.scale0 = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.scale_process = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes*4, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes*4, branch_planes*4, kernel_size=3, padding=1, groups=4, bias=False),\n",
        "                                    )\n",
        "\n",
        "\n",
        "        self.compression = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.shortcut = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        width = x.shape[-1]\n",
        "        height = x.shape[-2]\n",
        "        scale_list = []\n",
        "\n",
        "        x_ = self.scale0(x)\n",
        "        scale_list.append(F.interpolate(self.scale1(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale2(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale3(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale4(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "\n",
        "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
        "\n",
        "        out = self.compression(torch.cat([x_,scale_out], 1)) + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PagFM(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, after_relu=False, with_channel=False, BatchNorm=nn.BatchNorm2d):\n",
        "        super(PagFM, self).__init__()\n",
        "        self.with_channel = with_channel\n",
        "        self.after_relu = after_relu\n",
        "        self.f_x = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, mid_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(mid_channels)\n",
        "                                )\n",
        "        self.f_y = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, mid_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(mid_channels)\n",
        "                                )\n",
        "        if with_channel:\n",
        "            self.up = nn.Sequential(\n",
        "                                    nn.Conv2d(mid_channels, in_channels,\n",
        "                                              kernel_size=1, bias=False),\n",
        "                                    BatchNorm(in_channels)\n",
        "                                   )\n",
        "        if after_relu:\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        input_size = x.size()\n",
        "        if self.after_relu:\n",
        "            y = self.relu(y)\n",
        "            x = self.relu(x)\n",
        "\n",
        "        y_q = self.f_y(y)\n",
        "        y_q = F.interpolate(y_q, size=[input_size[2], input_size[3]],\n",
        "                            mode='bilinear', align_corners=False)\n",
        "        x_k = self.f_x(x)\n",
        "\n",
        "        if self.with_channel:\n",
        "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
        "        else:\n",
        "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
        "\n",
        "        y = F.interpolate(y, size=[input_size[2], input_size[3]],\n",
        "                            mode='bilinear', align_corners=False)\n",
        "        x = (1-sim_map)*x + sim_map*y\n",
        "\n",
        "        return x\n",
        "\n",
        "class Light_Bag(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(Light_Bag, self).__init__()\n",
        "        self.conv_p = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "        self.conv_i = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "\n",
        "        p_add = self.conv_p((1-edge_att)*i + p)\n",
        "        i_add = self.conv_i(i + edge_att*p)\n",
        "\n",
        "        return p_add + i_add\n",
        "\n",
        "\n",
        "class DDFMv2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(DDFMv2, self).__init__()\n",
        "        self.conv_p = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "        self.conv_i = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "\n",
        "        p_add = self.conv_p((1-edge_att)*i + p)\n",
        "        i_add = self.conv_i(i + edge_att*p)\n",
        "\n",
        "        return p_add + i_add\n",
        "\n",
        "class Bag(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(Bag, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=3, padding=1, bias=False)\n",
        "                                )\n",
        "\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "        return self.conv(edge_att*p + (1-edge_att)*i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "\n",
        "#     x = torch.rand(4, 64, 32, 64).cuda()\n",
        "#     y = torch.rand(4, 64, 32, 64).cuda()\n",
        "#     z = torch.rand(4, 64, 32, 64).cuda()\n",
        "#     net = PagFM(64, 16, with_channel=True).cuda()\n",
        "\n",
        "#     out = net(x,y)"
      ],
      "metadata": {
        "id": "Y8nRsMxdkK5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PIDNET**"
      ],
      "metadata": {
        "id": "IpNmE3FTjJRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "# from .model_utils import BasicBlock, Bottleneck, segmenthead, DAPPM, PAPPM, PagFM, Bag, Light_Bag\n",
        "import logging\n",
        "\n",
        "BatchNorm2d = nn.BatchNorm2d\n",
        "bn_mom = 0.1\n",
        "algc = False\n",
        "\n",
        "\n",
        "\n",
        "class PIDNet(nn.Module):\n",
        "\n",
        "    def __init__(self, m=2, n=3, num_classes=151, planes=64, ppm_planes=96, head_planes=128, augment=True):\n",
        "        super(PIDNet, self).__init__()\n",
        "        self.augment = augment\n",
        "\n",
        "        # I Branch\n",
        "        self.conv1 =  nn.Sequential(\n",
        "                          nn.Conv2d(3,planes,kernel_size=3, stride=2, padding=1),\n",
        "                          BatchNorm2d(planes, momentum=bn_mom),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                          nn.Conv2d(planes,planes,kernel_size=3, stride=2, padding=1),\n",
        "                          BatchNorm2d(planes, momentum=bn_mom),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                      )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(BasicBlock, planes, planes, m)\n",
        "        self.layer2 = self._make_layer(BasicBlock, planes, planes * 2, m, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, planes * 2, planes * 4, n, stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, planes * 4, planes * 8, n, stride=2)\n",
        "        self.layer5 =  self._make_layer(Bottleneck, planes * 8, planes * 8, 2, stride=2)\n",
        "\n",
        "        # P Branch\n",
        "        self.compression3 = nn.Sequential(\n",
        "                                          nn.Conv2d(planes * 4, planes * 2, kernel_size=1, bias=False),\n",
        "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                          )\n",
        "\n",
        "        self.compression4 = nn.Sequential(\n",
        "                                          nn.Conv2d(planes * 8, planes * 2, kernel_size=1, bias=False),\n",
        "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                          )\n",
        "        self.pag3 = PagFM(planes * 2, planes)\n",
        "        self.pag4 = PagFM(planes * 2, planes)\n",
        "\n",
        "        self.layer3_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
        "        self.layer4_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
        "        self.layer5_ = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
        "\n",
        "        # D Branch\n",
        "        if m == 2:\n",
        "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes)\n",
        "            self.layer4_d = self._make_layer(Bottleneck, planes, planes, 1)\n",
        "            self.diff3 = nn.Sequential(\n",
        "                                        nn.Conv2d(planes * 4, planes, kernel_size=3, padding=1, bias=False),\n",
        "                                        BatchNorm2d(planes, momentum=bn_mom),\n",
        "                                        )\n",
        "            self.diff4 = nn.Sequential(\n",
        "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                     )\n",
        "            self.spp = PAPPM(planes * 16, ppm_planes, planes * 4)\n",
        "            self.dfm = Light_Bag(planes * 4, planes * 4)\n",
        "        else:\n",
        "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
        "            self.layer4_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
        "            self.diff3 = nn.Sequential(\n",
        "                                        nn.Conv2d(planes * 4, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                        BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                        )\n",
        "            self.diff4 = nn.Sequential(\n",
        "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                     )\n",
        "            self.spp = DAPPM(planes * 16, ppm_planes, planes * 4)\n",
        "            self.dfm = Bag(planes * 4, planes * 4)\n",
        "\n",
        "        self.layer5_d = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
        "\n",
        "        # Prediction Head\n",
        "        if self.augment:\n",
        "            self.seghead_p = segmenthead(planes * 2, head_planes, num_classes)\n",
        "            self.seghead_d = segmenthead(planes * 2, planes, 1)\n",
        "\n",
        "        self.final_layer = segmenthead(planes * 4, head_planes, num_classes)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample))\n",
        "        inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            if i == (blocks-1):\n",
        "                layers.append(block(inplanes, planes, stride=1, no_relu=True))\n",
        "            else:\n",
        "                layers.append(block(inplanes, planes, stride=1, no_relu=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_single_layer(self, block, inplanes, planes, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
        "            )\n",
        "\n",
        "        layer = block(inplanes, planes, stride, downsample, no_relu=True)\n",
        "\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        width_output = x.shape[-1] // 8\n",
        "        height_output = x.shape[-2] // 8\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(self.layer2(self.relu(x)))\n",
        "        x_ = self.layer3_(x)\n",
        "        x_d = self.layer3_d(x)\n",
        "\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x_ = self.pag3(x_, self.compression3(x))\n",
        "        x_d = x_d + F.interpolate(\n",
        "                        self.diff3(x),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "        if self.augment:\n",
        "            temp_p = x_\n",
        "\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x_ = self.layer4_(self.relu(x_))\n",
        "        x_d = self.layer4_d(self.relu(x_d))\n",
        "\n",
        "        x_ = self.pag4(x_, self.compression4(x))\n",
        "        x_d = x_d + F.interpolate(\n",
        "                        self.diff4(x),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "        if self.augment:\n",
        "            temp_d = x_d\n",
        "\n",
        "        x_ = self.layer5_(self.relu(x_))\n",
        "        x_d = self.layer5_d(self.relu(x_d))\n",
        "        x = F.interpolate(\n",
        "                        self.spp(self.layer5(x)),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "\n",
        "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
        "\n",
        "        if self.augment:\n",
        "            x_extra_p = self.seghead_p(temp_p)\n",
        "            x_extra_d = self.seghead_d(temp_d)\n",
        "            return [x_extra_p, x_, x_extra_d]\n",
        "        else:\n",
        "            return x_\n",
        "\n",
        "def get_seg_model(cfg, imgnet_pretrained):\n",
        "\n",
        "    if 's' in cfg.MODEL.NAME:\n",
        "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=32, ppm_planes=96, head_planes=128, augment=True)\n",
        "    elif 'm' in cfg.MODEL.NAME:\n",
        "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=96, head_planes=128, augment=True)\n",
        "    else:\n",
        "        model = PIDNet(m=3, n=4, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=112, head_planes=256, augment=True)\n",
        "\n",
        "    if imgnet_pretrained:\n",
        "        pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_state = {k: v for k, v in pretrained_state.items() if (k in model_dict and v.shape == model_dict[k].shape)}\n",
        "        model_dict.update(pretrained_state)\n",
        "        msg = 'Loaded {} parameters!'.format(len(pretrained_state))\n",
        "        logging.info('Attention!!!')\n",
        "        logging.info(msg)\n",
        "        logging.info('Over!!!')\n",
        "        model.load_state_dict(model_dict, strict = False)\n",
        "    else:\n",
        "        pretrained_dict = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')\n",
        "        if 'state_dict' in pretrained_dict:\n",
        "            pretrained_dict = pretrained_dict['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
        "        msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
        "        logging.info('Attention!!!')\n",
        "        logging.info(msg)\n",
        "        logging.info('Over!!!')\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict, strict = False)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_pred_model(name, num_classes):\n",
        "\n",
        "    if 's' in name:\n",
        "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=32, ppm_planes=96, head_planes=128, augment=False)\n",
        "    elif 'm' in name:\n",
        "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=64, ppm_planes=96, head_planes=128, augment=False)\n",
        "    else:\n",
        "        model = PIDNet(m=3, n=4, num_classes=num_classes, planes=64, ppm_planes=112, head_planes=256, augment=False)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ohkP0MNCjHQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model configuration\n",
        "m = 2\n",
        "n = 3\n",
        "num_classes = 151\n",
        "planes = 64\n",
        "ppm_planes = 96\n",
        "head_planes = 128\n",
        "augment = False\n",
        "\n",
        "# Create an instance of the model\n",
        "model = PIDNet(m=m, n=n, num_classes=num_classes, planes=planes, ppm_planes=ppm_planes, head_planes=head_planes, augment=augment)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d56Vjj7LIq99",
        "outputId": "5ffa590e-d3dd-4b36-8e62-aa382c5021be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIDNet(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "  )\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (compression3): Sequential(\n",
            "    (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (compression4): Sequential(\n",
            "    (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (pag3): PagFM(\n",
            "    (f_x): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (f_y): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (pag4): PagFM(\n",
            "    (f_x): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (f_y): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3_): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4_): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer5_): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer3_d): BasicBlock(\n",
            "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4_d): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (diff3): Sequential(\n",
            "    (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (diff4): Sequential(\n",
            "    (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (spp): PAPPM(\n",
            "    (scale1): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=5, stride=2, padding=2)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (scale2): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=9, stride=4, padding=4)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (scale3): Sequential(\n",
            "      (0): AvgPool2d(kernel_size=17, stride=8, padding=8)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (scale4): Sequential(\n",
            "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (scale0): Sequential(\n",
            "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(1024, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (scale_process): Sequential(\n",
            "      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "    )\n",
            "    (compression): Sequential(\n",
            "      (0): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (shortcut): Sequential(\n",
            "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (dfm): Light_Bag(\n",
            "    (conv_p): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_i): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer5_d): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final_layer): segmenthead(\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 151, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATASET**"
      ],
      "metadata": {
        "id": "hySBkh_7K30B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZBaAa5xK6Jj",
        "outputId": "92902e7f-0993-44cd-b5c6-796eca62efc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os\n",
        "import requests\n",
        "import hashlib\n",
        "from tqdm import tqdm\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "bSkPKT2eMHWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some helper functions to download the dataset\n",
        "# this code comes mainly from gluoncv.utils\n",
        "def check_sha1(filename, sha1_hash):\n",
        "    \"\"\"Check whether the sha1 hash of the file content matches the expected hash.\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename : str\n",
        "        Path to the file.\n",
        "    sha1_hash : str\n",
        "        Expected sha1 hash in hexadecimal digits.\n",
        "    Returns\n",
        "    -------\n",
        "    bool\n",
        "        Whether the file content matches the expected hash.\n",
        "    \"\"\"\n",
        "    sha1 = hashlib.sha1()\n",
        "    with open(filename, 'rb') as f:\n",
        "        while True:\n",
        "            data = f.read(1048576)\n",
        "            if not data:\n",
        "                break\n",
        "            sha1.update(data)\n",
        "\n",
        "    sha1_file = sha1.hexdigest()\n",
        "    l = min(len(sha1_file), len(sha1_hash))\n",
        "    return sha1.hexdigest()[0:l] == sha1_hash[0:l]\n",
        "\n",
        "def download(url, path=None, overwrite=False, sha1_hash=None):\n",
        "    \"\"\"Download an given URL\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : str\n",
        "        URL to download\n",
        "    path : str, optional\n",
        "        Destination path to store downloaded file. By default stores to the\n",
        "        current directory with same name as in url.\n",
        "    overwrite : bool, optional\n",
        "        Whether to overwrite destination file if already exists.\n",
        "    sha1_hash : str, optional\n",
        "        Expected sha1 hash in hexadecimal digits. Will ignore existing file when hash is specified\n",
        "        but doesn't match.\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The file path of the downloaded file.\n",
        "    \"\"\"\n",
        "    if path is None:\n",
        "        fname = url.split('/')[-1]\n",
        "    else:\n",
        "        path = os.path.expanduser(path)\n",
        "        if os.path.isdir(path):\n",
        "            fname = os.path.join(path, url.split('/')[-1])\n",
        "        else:\n",
        "            fname = path\n",
        "\n",
        "    if overwrite or not os.path.exists(fname) or (sha1_hash and not check_sha1(fname, sha1_hash)):\n",
        "        dirname = os.path.dirname(os.path.abspath(os.path.expanduser(fname)))\n",
        "        if not os.path.exists(dirname):\n",
        "            os.makedirs(dirname)\n",
        "\n",
        "        print('Downloading %s from %s...'%(fname, url))\n",
        "        r = requests.get(url, stream=True)\n",
        "        if r.status_code != 200:\n",
        "            raise RuntimeError(\"Failed downloading url %s\"%url)\n",
        "        total_length = r.headers.get('content-length')\n",
        "        with open(fname, 'wb') as f:\n",
        "            if total_length is None: # no content length header\n",
        "                for chunk in r.iter_content(chunk_size=1024):\n",
        "                    if chunk: # filter out keep-alive new chunks\n",
        "                        f.write(chunk)\n",
        "            else:\n",
        "                total_length = int(total_length)\n",
        "                for chunk in tqdm(r.iter_content(chunk_size=1024),\n",
        "                                  total=int(total_length / 1024. + 0.5),\n",
        "                                  unit='KB', unit_scale=False, dynamic_ncols=True):\n",
        "                    f.write(chunk)\n",
        "\n",
        "        if sha1_hash and not check_sha1(fname, sha1_hash):\n",
        "            raise UserWarning('File {} is downloaded but the content hash does not match. ' \\\n",
        "                              'The repo may be outdated or download may be incomplete. ' \\\n",
        "                              'If the \"repo_url\" is overridden, consider switching to ' \\\n",
        "                              'the default repo.'.format(fname))\n",
        "\n",
        "    return fname\n",
        "\n",
        "def download_ade(path, overwrite=False):\n",
        "\n",
        "    \"\"\"Download ADE20K\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "      Location of the downloaded files.\n",
        "    overwrite : bool, optional\n",
        "      Whether to overwrite destination file if already exists.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "    _AUG_DOWNLOAD_URLS = [\n",
        "      ('http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip', '219e1696abb36c8ba3a3afe7fb2f4b4606a897c7'),\n",
        "      ('http://data.csail.mit.edu/places/ADEchallenge/release_test.zip', 'e05747892219d10e9243933371a497e905a4860c'),]\n",
        "    download_dir = os.path.join(path, 'downloads')\n",
        "    if not os.path.exists(download_dir):\n",
        "        os.mkdir(download_dir)\n",
        "    for url, checksum in _AUG_DOWNLOAD_URLS:\n",
        "        filename = download(url, path=download_dir, overwrite=overwrite, sha1_hash=checksum)\n",
        "        # extract\n",
        "        with zipfile.ZipFile(filename,\"r\") as zip_ref:\n",
        "            zip_ref.extractall(path=path)"
      ],
      "metadata": {
        "id": "MyHU5VbsMBBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/content/\"\n",
        "dataset_path = root + \"ADEChallengeData2016/images/\"\n",
        "training_data = \"training/\"\n",
        "val_data = \"validation/\""
      ],
      "metadata": {
        "id": "AaprfajcMOcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to your training and validation data\n",
        "training_data_path = os.path.join(dataset_path, training_data)\n",
        "val_data_path = os.path.join(dataset_path, val_data)"
      ],
      "metadata": {
        "id": "FwHQXFF1s0Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_ade(root, overwrite=False)"
      ],
      "metadata": {
        "id": "SYALBBolMP6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bad075-88d7-4afa-a53f-c503583cebdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /content/downloads/ADEChallengeData2016.zip from http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "944710KB [00:16, 57045.89KB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /content/downloads/release_test.zip from http://data.csail.mit.edu/places/ADEchallenge/release_test.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 206856/206856 [00:03<00:00, 53901.51KB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size that we are going to use\n",
        "IMG_SIZE = 128\n",
        "# Our images are RGB (3 channels)\n",
        "N_CHANNELS = 3\n",
        "# Scene Parsing has 150 classes + `not labeled`\n",
        "N_CLASSES = 151"
      ],
      "metadata": {
        "id": "GjRxtbOmMhto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "TRAINSET_SIZE = len(glob(dataset_path + training_data + \"*.jpg\"))\n",
        "print(f\"The Training Dataset contains {TRAINSET_SIZE} images.\")\n",
        "\n",
        "VALSET_SIZE = len(glob(dataset_path + val_data + \"*.jpg\"))\n",
        "print(f\"The Validation Dataset contains {VALSET_SIZE} images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHLnnjkdMk5w",
        "outputId": "56c00955-b214-4eeb-a4f9-a87c958b17be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Training Dataset contains 20210 images.\n",
            "The Validation Dataset contains 2000 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-m3dxPzycs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# # Define a custom PyTorch Dataset\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self, data_path, transform=None, target_size=(512, 512)):\n",
        "#         self.data_path = data_path\n",
        "#         self.transform = transform\n",
        "#         self.target_size = target_size\n",
        "#         self.file_list = [file for file in os.listdir(data_path) if file.endswith(\".jpg\")]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.file_list)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         img_path = os.path.join(self.data_path, self.file_list[idx])\n",
        "#         image = Image.open(img_path)\n",
        "#         image = np.array(image)\n",
        "\n",
        "#         mask_path = img_path.replace(\"images\", \"annotations\").replace(\"jpg\", \"png\")\n",
        "#         mask = Image.open(mask_path)\n",
        "#         mask = np.array(mask)\n",
        "#         mask = np.where(mask == 255, 0, mask)\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "#             mask = self.transform(mask)\n",
        "\n",
        "#         return {\"image\": image, \"segmentation_mask\": mask}\n",
        "\n",
        "\n",
        "# # Create dataset instances\n",
        "# train_dataset = CustomDataset(training_data_path)  # Add transform parameter if needed\n",
        "# val_dataset = CustomDataset(val_data_path)  # Add transform parameter if needed\n",
        "\n",
        "# # Now you have train_dataset and val_dataset containing the image and segmentation mask pairs\n",
        "# # You can access them using train_dataset[idx] or val_dataset[idx]\n",
        "\n",
        "# # Example usage\n",
        "# for data in train_dataset:\n",
        "#     image = data['image']\n",
        "#     mask = data['segmentation_mask']\n",
        "#     # Use the image and mask as needed in your training loop\n"
      ],
      "metadata": {
        "id": "b52WKl_pulHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Define a function to visualize a subset of data\n",
        "# def visualize_dataset(dataset, num_samples=5):\n",
        "#     fig, axes = plt.subplots(2, num_samples, figsize=(15, 5))\n",
        "#     fig.suptitle(\"Visualizing Subset of Data\", fontsize=16)\n",
        "\n",
        "#     for i in range(num_samples):\n",
        "#         sample = dataset[i]\n",
        "#         image = sample['image']\n",
        "#         mask = sample['segmentation_mask']\n",
        "\n",
        "#         axes[0, i].imshow(image)\n",
        "#         axes[0, i].set_title(f\"Sample {i + 1}\\nImage\")\n",
        "#         axes[0, i].axis('off')\n",
        "\n",
        "#         axes[1, i].imshow(mask, cmap='jet', vmin=0, vmax=150)  # Assuming there are 150 classes\n",
        "#         axes[1, i].set_title(f\"Sample {i + 1}\\nMask\")\n",
        "#         axes[1, i].axis('off')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # Visualize a random subset of the training dataset\n",
        "# visualize_dataset(train_dataset, num_samples=5)\n",
        "\n",
        "# # Visualize a random subset of the validation dataset\n",
        "# visualize_dataset(val_dataset, num_samples=5)\n"
      ],
      "metadata": {
        "id": "LSIGmM_MlTb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.0001\n",
        "batch_size = 16\n"
      ],
      "metadata": {
        "id": "aX2wgXQywRuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# # Define data transformations\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((256, 256)),  # Resize to a specific size\n",
        "#     transforms.RandomHorizontalFlip(),  # Randomly flip horizontally\n",
        "#     transforms.ToTensor(),  # Convert PIL image to PyTorch tensor\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
        "# ])\n",
        "\n",
        "# # Create dataset instances with the defined transformations\n",
        "# train_dataset = CustomDataset(training_data_path, transform=transform)\n",
        "# val_dataset = CustomDataset(val_data_path, transform=transform)\n"
      ],
      "metadata": {
        "id": "QcmKlH0yxV1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self, data_path, transform=None, target_size=(512, 512)):\n",
        "#         self.data_path = data_path\n",
        "#         self.transform = transform\n",
        "#         self.target_size = target_size\n",
        "#         self.file_list = [file for file in os.listdir(data_path) if file.endswith(\".jpg\")]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.file_list)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         img_path = os.path.join(self.data_path, self.file_list[idx])\n",
        "#         image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n",
        "#         mask_path = img_path.replace(\"images\", \"annotations\").replace(\"jpg\", \"png\")\n",
        "#         mask = Image.open(mask_path)\n",
        "#         mask = np.array(mask)\n",
        "#         mask = np.where(mask == 255, 0, mask)\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "#             mask = self.transform(mask)\n",
        "\n",
        "#         return {\"image\": image, \"segmentation_mask\": mask}\n",
        "\n",
        "# # Define data transformations\n",
        "# data_transform = transforms.Compose([\n",
        "#     transforms.Resize((512, 512)),  # Resize to the desired target size\n",
        "#     transforms.ToTensor(),\n",
        "#     # Add more transformations as needed\n",
        "# ])\n",
        "\n",
        "# # Create dataset instances with transformations\n",
        "# train_dataset = CustomDataset(training_data_path, transform=data_transform)\n",
        "# val_dataset = CustomDataset(val_data_path, transform=data_transform)\n"
      ],
      "metadata": {
        "id": "s3rgiASj4Zzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None, target_size=(512, 512)):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "        self.file_list = [file for file in os.listdir(data_path) if file.endswith(\".jpg\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.data_path, self.file_list[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n",
        "        mask_path = img_path.replace(\"images\", \"annotations\").replace(\"jpg\", \"png\")\n",
        "        mask = Image.open(mask_path)\n",
        "        mask = np.array(mask)\n",
        "        mask = np.where(mask == 255, 0, mask)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return {\"image\": image, \"segmentation_mask\": mask}\n",
        "\n",
        "    # def mask_transform(self, mask):\n",
        "    # #     return transforms.ToTensor()(mask).float()\n",
        "    # def mask_transform(self, mask):\n",
        "    #   mask_pil = Image.fromarray(mask)  # Convert numpy mask to PIL Image\n",
        "    #   mask_transform = transforms.Compose([\n",
        "    #       transforms.Resize(self.target_size),  # Resize masks to the same target size\n",
        "    #       transforms.ToTensor(),\n",
        "    #   ])\n",
        "      # return mask_transform(mask_pil).float()\n",
        "\n",
        "    def mask_transform(self, mask):\n",
        "            mask_pil = Image.fromarray(mask)  # Convert numpy mask to PIL Image\n",
        "            mask_transform = transforms.Compose([\n",
        "                transforms.Resize(self.target_size),  # Resize masks to the same target size\n",
        "                transforms.ToTensor(),\n",
        "            ])\n",
        "            return mask_transform(mask_pil).squeeze(0)\n",
        "\n",
        "# Define data transformations\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # Resize to the desired target size\n",
        "    transforms.ToTensor(),\n",
        "    # Add more transformations as needed\n",
        "])\n",
        "\n",
        "# Create dataset instances with transformations\n",
        "train_dataset = CustomDataset(training_data_path, transform=data_transform)\n",
        "val_dataset = CustomDataset(val_data_path, transform=data_transform)\n"
      ],
      "metadata": {
        "id": "RoXFVlQN49e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***full set, not subset***"
      ],
      "metadata": {
        "id": "QpXN4-H2Ww7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define your custom dataset and dataloaders\n",
        "# train_dataset = CustomDataset(train_files, transform=train_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# val_dataset = CustomDataset(val_files, transform=val_transform)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define your model\n",
        "# model = YourCustomModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "io9WmzLAPqDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**subset**"
      ],
      "metadata": {
        "id": "spP9elC0WuCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "5irLPHKMXpAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "# Choose indices for the subsets\n",
        "train_subset_indices = list(range(2000))   # Choose the first 2000 samples\n",
        "val_subset_indices = list(range(200))     # Choose the first 2000 samples for validation as well\n",
        "\n",
        "# Create subsets of the datasets using the chosen indices\n",
        "train_subset = Subset(train_dataset, train_subset_indices)\n",
        "val_subset = Subset(val_dataset, val_subset_indices)\n",
        "\n",
        "# Define dataloaders for the subsets\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "XOfzpxNBWpNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        inputs, targets = batch['image'], batch['segmentation_mask']\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Resize the target masks to match the size of the model's outputs\n",
        "        targets_resized = torch.nn.functional.interpolate(targets.unsqueeze(1), size=outputs.size()[2:], mode='nearest')\n",
        "\n",
        "        # Convert target masks to 3D tensors\n",
        "        targets_3d = targets_resized.squeeze(1)\n",
        "\n",
        "        # Calculate the loss\n",
        "        # loss = criterion(outputs, targets_3d)\n",
        "        loss = criterion(outputs, targets_3d.long())\n",
        "        print(loss)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    checkpoint_path = f'checkpoint_epoch_{epoch}.pth'\n",
        "    torch.save(model.state_dict(), checkpoint_path)\n",
        "    print(f'Saved checkpoint: {checkpoint_path}')\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for batch in val_dataloader:\n",
        "            inputs, targets = batch['image'], batch['segmentation_mask']\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Resize the target masks for validation as well\n",
        "            targets_resized = torch.nn.functional.interpolate(targets.unsqueeze(1), size=outputs.size()[2:], mode='nearest')\n",
        "\n",
        "            # Convert target masks to 3D tensors\n",
        "            targets_3d = targets_resized.squeeze(1)\n",
        "\n",
        "            val_loss += criterion(outputs, targets_3d.long())\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training Loss: {loss:.4f} - Validation Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaVGonPsRZ_t",
        "outputId": "67bbc177-2942-4a9e-ead7-21b69a3c6578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.0739, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.9750, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.8979, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.8282, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.7387, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.6837, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.5420, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.4265, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.2609, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(5.0673, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.9814, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.9101, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.7099, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.5705, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.5783, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.5384, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.3340, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.3416, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.5431, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.1228, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.0376, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(4.0645, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.9040, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.9278, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.8386, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.8556, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.6706, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.7584, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.5932, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.5273, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.4370, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.4794, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.5449, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.5586, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.4104, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.2181, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.2709, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.3743, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.2643, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.3273, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.1715, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.1555, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.1715, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.0453, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.9940, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.0514, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.0162, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(3.1135, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.9218, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.9582, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8675, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8761, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.9113, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8521, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8149, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7157, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7474, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6789, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7822, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6621, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7384, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8306, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6753, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8290, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7149, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5994, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.9017, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.8146, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5458, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7575, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5499, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6323, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5042, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7329, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5298, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4734, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5385, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4340, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4444, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.7246, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5618, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4304, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4692, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5753, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5256, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4607, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6385, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6060, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5455, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4322, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5058, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5422, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.6221, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4048, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4399, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.3778, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4325, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5344, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.3760, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4565, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4187, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.4129, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.3476, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.3848, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.3389, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2703, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.3273, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2290, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2651, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1490, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1506, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1570, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2917, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5459, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.5342, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2248, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2022, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1612, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2008, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1848, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1755, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1155, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1851, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.2519, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1329, grad_fn=<NllLoss2DBackward0>)\n",
            "Saved checkpoint: checkpoint_epoch_0.pth\n",
            "Epoch [1/10] - Training Loss: 2.1329 - Validation Loss: 25.6119\n",
            "tensor(2.0817, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1181, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1039, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0589, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0416, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0429, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1183, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0481, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0557, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0341, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0034, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.1507, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9674, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9426, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(2.0043, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9506, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9066, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9011, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9365, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9283, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9471, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8843, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.9180, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8635, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8782, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8766, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8563, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8421, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8302, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8392, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8223, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7895, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8042, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7882, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7915, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8157, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7650, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7564, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7648, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7860, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7552, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7280, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7251, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7363, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6911, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6952, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7367, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7017, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6631, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6920, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6555, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7223, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8745, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7357, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7137, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7025, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7384, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8085, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6898, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.8686, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6692, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7832, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6764, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7283, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6908, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6768, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6706, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7227, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.7270, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6512, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6035, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6371, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6510, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6237, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5305, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5857, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5682, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5850, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6047, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5188, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.6022, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5502, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5725, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4871, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4860, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5004, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4559, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4841, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5330, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4584, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4889, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4393, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4755, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.5905, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4611, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3829, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4746, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4238, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4386, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3965, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3770, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4427, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3805, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3609, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3518, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3295, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3672, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3388, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3716, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3189, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3105, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3426, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3192, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2839, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.4357, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3384, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3068, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2845, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3452, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3017, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3084, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2889, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2760, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3585, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3128, grad_fn=<NllLoss2DBackward0>)\n",
            "Saved checkpoint: checkpoint_epoch_1.pth\n",
            "Epoch [2/10] - Training Loss: 1.3128 - Validation Loss: 21.0068\n",
            "tensor(1.2674, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2441, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3069, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2705, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2746, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2321, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2693, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2265, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2321, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1565, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1768, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1913, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1478, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1651, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1583, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1798, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1279, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.3108, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2037, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.2528, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1987, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1172, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1534, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1254, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1363, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1562, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1250, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.1054, grad_fn=<NllLoss2DBackward0>)\n",
            "tensor(1.0810, grad_fn=<NllLoss2DBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save checkpoint after each epoch\n",
        "# checkpoint_path = f'checkpoint_epoch_{epoch}.pth'\n",
        "# Save checkpoint after each epoch\n",
        "checkpoint_path = f'checkpoint_epoch_{epoch}.pth'\n",
        "torch.save(model.state_dict(), checkpoint_path)\n",
        "print(f'Saved checkpoint: {checkpoint_path}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zix8legwG3ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the trained model checkpoint\n",
        "loaded_checkpoint_path = 'checkpoint_epoch_0.pth'  # Replace with the actual checkpoint file path\n",
        "model.load_state_dict(torch.load(loaded_checkpoint_path))\n",
        "model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "id": "Yv3tz38Ldh5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDVBDOGneyec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load and preprocess the test image\n",
        "test_image_path = '/content/data/MyDrive/CNN_assignment/image_people.jpg'\n",
        "input_image = Image.open(test_image_path)\n",
        "\n",
        "# Apply preprocessing transforms\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "input_tensor = preprocess(input_image).unsqueeze(0)  # Add batch dimension\n"
      ],
      "metadata": {
        "id": "AHeNCrH5eI0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predictions = model(input_tensor)\n",
        "\n",
        "# Assuming predictions is a tensor with shape (batch_size, num_classes, height, width)\n",
        "# You can extract the predicted class labels for each pixel\n",
        "predicted_labels = predictions.argmax(dim=1).squeeze().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "mmmSYlOReXoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the original image\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(input_image)\n",
        "plt.title('Original Image')\n",
        "\n",
        "# Plot the predicted segmentation mask\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(predicted_labels, cmap='jet', vmin=0, vmax=num_classes-1)\n",
        "plt.title('Predicted Segmentation')\n",
        "\n",
        "# You can also visualize the ground truth mask if available\n",
        "# ground_truth_path = 'path_to_ground_truth_mask.png'\n",
        "# ground_truth_mask = Image.open(ground_truth_path)\n",
        "# plt.subplot(1, 3, 3)\n",
        "# plt.imshow(ground_truth_mask, cmap='jet', vmin=0, vmax=num_classes-1)\n",
        "# plt.title('Ground Truth')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sWW4qktNebss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}